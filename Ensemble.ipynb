{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load in our libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sklearn\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Going to use these 5 base models for the stacking\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "def gini(y, pred):\n",
    "    g = np.asarray(np.c_[y, pred, np.arange(len(y)) ], dtype=np.float)\n",
    "    g = g[np.lexsort((g[:,2], -1*g[:,1]))]\n",
    "    gs = g[:,0].cumsum().sum() / g[:,0].sum()\n",
    "    gs -= (len(y) + 1) / 2.\n",
    "    return gs / len(y)\n",
    "\n",
    "def gini_normalized(a, p):\n",
    "    return gini(a, p) / gini(a, a)\n",
    "\n",
    "def gini_lgb(preds, dtrain):\n",
    "    y = list(dtrain.get_label())\n",
    "    score = gini(y, preds) / gini(y, y)\n",
    "    return 'gini', score, True\n",
    "\n",
    "def calcginiindex(array):\n",
    "    array = array.flatten()\n",
    "    array += 0.0000001\n",
    "    array = np.sort(array)\n",
    "    index = np.arange(1,array.shape[0]+1)\n",
    "    n = array.shape[0]\n",
    "    return ((np.sum((2*index - n - 1)*array))/(n * np.sum(array)))\n",
    "\n",
    "def gini_xgb(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = gini_normalized(labels, preds)\n",
    "    return 'gini', gini_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "features = train.drop(['target', 'id'], axis = 1)\n",
    "targets = train.target.values\n",
    "\n",
    "unwanted = train.columns[train.columns.str.startswith('ps_calc_')]\n",
    "\n",
    "train = train.drop(unwanted, axis = 1)\n",
    "test = test.drop(unwanted, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling and stacking models\n",
    "### SklearnHelper For RF, ET, AD, GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some useful parameters which will come in handy later on\n",
    "ntrain = train.shape[0]\n",
    "ntest = test.shape[0]\n",
    "SEED = 42 # for reproducibility\n",
    "NFOLDS = 5 # set folds for out-of-fold prediction\n",
    "kf = KFold(ntrain, n_folds= NFOLDS, random_state=SEED)\n",
    "\n",
    "# Class to extend the Sklearn classifier\n",
    "class SklearnHelper(object):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        return self.clf.predict_proba(x)\n",
    "    \n",
    "    def fit(self,x,y):\n",
    "        return self.clf.fit(x,y)\n",
    "    \n",
    "    def feature_importances(self,x,y):\n",
    "        print(self.clf.fit(x,y).feature_importances_)\n",
    "    \n",
    "# Class to extend XGboost classifer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get predictions/new features from SklearnHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = 5\n",
    "skf = StratifiedKFold(n_splits=kfold, random_state=42)\n",
    "\n",
    "def get_oof(clf, x_train, y_train, x_test):\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((kfold, ntest))\n",
    "\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(skf.split(x_train, y_train)):\n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y_train[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "        y_te = y_train[test_index]\n",
    "        \n",
    "        clf.train(x_tr, y_tr)\n",
    "\n",
    "        oof_train[test_index] = clf.predict_proba(x_te)[:, 1]\n",
    "        train_pred = clf.predict_proba(x_tr)[:, 1]\n",
    "        oof_test_skf[i, :] = clf.predict_proba(x_test)[:, 1]\n",
    "        print(\"Fold :\", i,\"Train Gini:\", gini_normalized(train_pred, y_tr) ,\"Valid Gini:\", gini_normalized(oof_train[test_index], y_te))\n",
    "        \n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get predictions/new features from LightGBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_oof_lgb(x_train, y_train, x_test):\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((kfold, ntest))\n",
    "\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(x_train, y_train)):\n",
    "        X_train, X_valid = X[train_index], X[test_index]\n",
    "        y_train, y_valid = y[train_index], y[test_index]\n",
    "\n",
    "        # create dataset for lightgbm\n",
    "        lgb_train = lgb.Dataset(X_train, y_train)\n",
    "        lgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train)\n",
    "        \n",
    "\n",
    "        clf = lgb.train(lgb_params,\n",
    "                    lgb_train,\n",
    "                    num_boost_round=4000,\n",
    "                    valid_sets=lgb_eval,\n",
    "                    early_stopping_rounds=130,\n",
    "                    feval=gini_lgb, verbose_eval=500,\n",
    "                    learning_rates = lambda iter: 0.025 * (0.999 ** iter)\n",
    "                    )\n",
    "\n",
    "        oof_train[test_index] = (clf.predict(X_valid) > 0.5)\n",
    "        oof_test_skf[i, :] = (clf.predict(x_test) > 0.5)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get predictions/new features from XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_oof_xgb(x_train, y_train, x_test):\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((kfold, ntest))\n",
    "\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(skf.split(x_train, y_train)):\n",
    "        X_train, X_valid = X[train_index], X[test_index]\n",
    "        y_train, y_valid = y[train_index], y[test_index]\n",
    "        # Convert our data into XGBoost format\n",
    "        d_train = xgb.DMatrix(X_train, y_train)\n",
    "        d_valid = xgb.DMatrix(X_valid, y_valid)\n",
    "        d_test = xgb.DMatrix(x_test.values)\n",
    "        watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "\n",
    "        # Train the model! We pass in a max of 2,000 rounds (with early stopping after 100)\n",
    "        # and the custom metric (maximize=True tells xgb that higher metric is better)\n",
    "        clf = xgb.train(xgb_params, d_train, 4000, watchlist, early_stopping_rounds=130, feval=gini_xgb, maximize=True, verbose_eval=500,\n",
    "                       learning_rates = lambda iter, ed: 0.025 * (0.998 ** iter))\n",
    "\n",
    "        oof_train[test_index] = (clf.predict(d_valid) > 0.5)\n",
    "        oof_test_skf[i, :] = (clf.predict(d_test) > 0.5)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-218-1e45d4effff3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtest_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Damygame\\Anaconda2\\lib\\site-packages\\pandas\\core\\generic.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   2968\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2969\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2970\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2971\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2972\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'id'"
     ]
    }
   ],
   "source": [
    "X = train.drop(['id', 'target'], axis = 1).values\n",
    "y = train.target.values\n",
    "\n",
    "test_id = test.id.values\n",
    "test = test.drop('id', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST\n",
      "('Fold :', 0, 'Train Gini:', 0.31587930721959806, 'Valid Gini:', 0.033468833637298273)\n",
      "('Fold :', 1, 'Train Gini:', 0.30676553131541462, 'Valid Gini:', 0.31803738981901836)\n",
      "('Fold :', 2, 'Train Gini:', 0.30675264653999368, 'Valid Gini:', 0.31752042090380284)\n",
      "('Fold :', 3, 'Train Gini:', 0.30746164616239946, 'Valid Gini:', 0.31649170078492367)\n",
      "('Fold :', 4, 'Train Gini:', 0.30875467048488037, 'Valid Gini:', 0.31592191628930205)\n",
      "('New best gini:', 0.31200791921807464)\n"
     ]
    }
   ],
   "source": [
    "best_gini = 0\n",
    "rf_params = {\n",
    "    'n_jobs': 6,\n",
    "    'n_estimators': 40,\n",
    "    'warm_start': True, \n",
    "    'max_features': 37,\n",
    "    'max_depth': 15\n",
    "}\n",
    "rf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\n",
    "\n",
    "print('RANDOM FOREST')\n",
    "rf_oof_train, rf_oof_test = get_oof(rf,X, y, test) # Random Forest\n",
    "curr_gini = calcginiindex(rf_oof_test)\n",
    "if curr_gini > best_gini:\n",
    "    print('New best gini:', curr_gini)\n",
    "    best_gini = curr_gini\n",
    "    best_params = pd.DataFrame(rf_params, index=[1])\n",
    "else:\n",
    "    print('Curr gini:', curr_gini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "('Fold :', 0, 'Train Gini:', 0.064682245742869432, 'Valid Gini:', 0.036497715991040923)\n",
      "('Fold :', 1, 'Train Gini:', 0.063224794941622642, 'Valid Gini:', 0.032148094070969684)\n",
      "('Fold :', 2, 'Train Gini:', 0.057848795808981911, 'Valid Gini:', 0.036702423667169942)\n",
      "('Fold :', 3, 'Train Gini:', 0.061834802632231824, 'Valid Gini:', 0.036345915731020688)\n",
      "('Fold :', 4, 'Train Gini:', 0.061748761597841699, 'Valid Gini:', 0.039186190963190148)\n",
      "('New best gini:', 0.21572119122892536)\n"
     ]
    }
   ],
   "source": [
    "best_gini = 0\n",
    "dt_params = {\n",
    "    'max_features': 37,\n",
    "    'max_depth': 20,\n",
    "    'max_leaf_nodes':130\n",
    "}\n",
    "dt = SklearnHelper(clf=DecisionTreeClassifier, seed=SEED, params=dt_params)\n",
    "\n",
    "print('Decision Tree')\n",
    "dt_oof_train, dt_oof_test = get_oof(dt,X, y, test) # Random Forest\n",
    "curr_gini = calcginiindex(dt_oof_test)\n",
    "if curr_gini > best_gini:\n",
    "    print('New best gini:', curr_gini)\n",
    "    best_gini = curr_gini\n",
    "    best_params = pd.DataFrame(dt_params, index=[1])\n",
    "else:\n",
    "    print('Curr gini:', curr_gini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXTRA TREES\n",
      "('Fold :', 0, 'Train Gini:', 0.5276635028812704, 'Valid Gini:', 0.03638232810262243)\n",
      "('Fold :', 1, 'Train Gini:', 0.51606517905262295, 'Valid Gini:', 0.52713584119592249)\n",
      "('Fold :', 2, 'Train Gini:', 0.51482675750572648, 'Valid Gini:', 0.53187893658813168)\n",
      "('Fold :', 3, 'Train Gini:', 0.51677015176940266, 'Valid Gini:', 0.52576297579359732)\n",
      "('Fold :', 4, 'Train Gini:', 0.5161111107254438, 'Valid Gini:', 0.52677931774240461)\n",
      "('New best gini:', 0.34544273823048977)\n"
     ]
    }
   ],
   "source": [
    "# Extra Trees Parameters\n",
    "et_params = {\n",
    "    'n_jobs': 6,\n",
    "    'n_estimators': 40,\n",
    "    'warm_start': True, \n",
    "    'max_features': 37,\n",
    "    'max_depth': 17  \n",
    "}\n",
    "print('EXTRA TREES')\n",
    "et = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\n",
    "\n",
    "et_oof_train, et_oof_test = get_oof(et, X, y, test) # Extra Trees\n",
    "\n",
    "curr_gini = calcginiindex(et_oof_test)\n",
    "if curr_gini > best_gini:\n",
    "    print('New best gini:', curr_gini)\n",
    "    best_gini = curr_gini\n",
    "    best_params = pd.DataFrame(et_params, index=[1])\n",
    "else:\n",
    "    print('Curr gini:', curr_gini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADABOOST\n",
      "('Fold :', 0, 'Train Gini:', 0.02937513804857288, 'Valid Gini:', 0.029498637856646977)\n",
      "('Fold :', 1, 'Train Gini:', 0.027900992771846579, 'Valid Gini:', 0.032083904283688854)\n",
      "('Fold :', 2, 'Train Gini:', 0.028262741880190803, 'Valid Gini:', 0.027240561320036463)\n",
      "('Fold :', 3, 'Train Gini:', 0.029047119671950509, 'Valid Gini:', 0.02360796730539369)\n",
      "('Fold :', 4, 'Train Gini:', 0.029163440434755383, 'Valid Gini:', 0.029680080751846933)\n",
      "('Curr gini:', 0.01285387891056696)\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost parameters\n",
    "ada_params = {\n",
    "    'n_estimators': 300,\n",
    "    'learning_rate' : 0.025,   \n",
    "}\n",
    "\n",
    "print('ADABOOST')\n",
    "ada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\n",
    "\n",
    "ada_oof_train, ada_oof_test = get_oof(ada, X, y, test) # AdaBoost \n",
    "\n",
    "curr_gini = calcginiindex(ada_oof_test)\n",
    "if curr_gini > best_gini:\n",
    "    print('New best gini:', curr_gini)\n",
    "    best_gini = curr_gini\n",
    "    best_params = pd.DataFrame(ada_params, index=[1])\n",
    "else:\n",
    "    print('Curr gini:', curr_gini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting parameters\n",
    "gb_params = {\n",
    "    'n_estimators': 200,\n",
    "    'max_features': 37,\n",
    "    'max_depth': 17,\n",
    "    'subsample': 0.8,\n",
    "}\n",
    "\n",
    "gb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\n",
    "\n",
    "print('GRADIENT BOOSTING')\n",
    "gb_oof_train, gb_oof_test = get_oof(gb,X, y, test) # Gradient Boost\n",
    "curr_gini = calcginiindex(gb_oof_test)\n",
    "if curr_gini > best_gini:\n",
    "    print('New best gini:', curr_gini)\n",
    "    best_gini = curr_gini\n",
    "    best_params = pd.DataFrame(gb_params, index=[1])\n",
    "else:\n",
    "    print('Curr gini:', curr_gini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 130 rounds.\n",
      "[500]\tvalid_0's gini: 0.275826\n",
      "[1000]\tvalid_0's gini: 0.280338\n",
      "Early stopping, best iteration is:\n",
      "[1359]\tvalid_0's gini: 0.280923\n",
      "Training until validation scores don't improve for 130 rounds.\n",
      "[500]\tvalid_0's gini: 0.279104\n",
      "[1000]\tvalid_0's gini: 0.282039\n",
      "Early stopping, best iteration is:\n",
      "[1058]\tvalid_0's gini: 0.282115\n",
      "Training until validation scores don't improve for 130 rounds.\n",
      "[500]\tvalid_0's gini: 0.276888\n",
      "[1000]\tvalid_0's gini: 0.279012\n",
      "Early stopping, best iteration is:\n",
      "[1189]\tvalid_0's gini: 0.279377\n",
      "Training until validation scores don't improve for 130 rounds.\n",
      "[500]\tvalid_0's gini: 0.283432\n",
      "[1000]\tvalid_0's gini: 0.286575\n",
      "Early stopping, best iteration is:\n",
      "[911]\tvalid_0's gini: 0.286634\n",
      "Training until validation scores don't improve for 130 rounds.\n",
      "[500]\tvalid_0's gini: 0.269399\n",
      "[1000]\tvalid_0's gini: 0.273026\n",
      "Early stopping, best iteration is:\n",
      "[1137]\tvalid_0's gini: 0.273242\n"
     ]
    }
   ],
   "source": [
    "lgb_params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'min_sum_hessian_in_leaf': 10,\n",
    "    'min_gain_to_split': 0.65,\n",
    "    'poisson_max_delta_step': 1.8,\n",
    "    'num_leaves': 31,\n",
    "    #'learning_rate': 0.025,\n",
    "    'feature_fraction': 0.4,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'max_depth': 7,\n",
    "    'verbose': 2\n",
    "}\n",
    "\n",
    "lgb_oof_train, lgb_oof_test = get_oof_lgb(X, y, test) # LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-gini:0.023568\tvalid-gini:0.030105\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 130 rounds.\n",
      "[500]\ttrain-gini:0.40022\tvalid-gini:0.278484\n",
      "[1000]\ttrain-gini:0.431121\tvalid-gini:0.27982\n",
      "Stopping. Best iteration:\n",
      "[1033]\ttrain-gini:0.432084\tvalid-gini:0.279847\n",
      "\n",
      "[0]\ttrain-gini:0.023179\tvalid-gini:0.036347\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 130 rounds.\n",
      "[500]\ttrain-gini:0.397777\tvalid-gini:0.285831\n",
      "[1000]\ttrain-gini:0.429074\tvalid-gini:0.287582\n",
      "Stopping. Best iteration:\n",
      "[1322]\ttrain-gini:0.436728\tvalid-gini:0.288112\n",
      "\n",
      "[0]\ttrain-gini:0.023073\tvalid-gini:0.02586\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 130 rounds.\n",
      "[500]\ttrain-gini:0.400694\tvalid-gini:0.282228\n",
      "Stopping. Best iteration:\n",
      "[690]\ttrain-gini:0.417463\tvalid-gini:0.282968\n",
      "\n",
      "[0]\ttrain-gini:0.062483\tvalid-gini:0.060343\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 130 rounds.\n",
      "[500]\ttrain-gini:0.399104\tvalid-gini:0.288478\n",
      "[1000]\ttrain-gini:0.429505\tvalid-gini:0.291202\n",
      "[1500]\ttrain-gini:0.439092\tvalid-gini:0.291563\n",
      "[2000]\ttrain-gini:0.442635\tvalid-gini:0.29163\n",
      "Stopping. Best iteration:\n",
      "[1918]\ttrain-gini:0.442297\tvalid-gini:0.291635\n",
      "\n",
      "[0]\ttrain-gini:0.026541\tvalid-gini:0.014679\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 130 rounds.\n",
      "[500]\ttrain-gini:0.401695\tvalid-gini:0.275911\n",
      "[1000]\ttrain-gini:0.433082\tvalid-gini:0.277004\n",
      "[1500]\ttrain-gini:0.442618\tvalid-gini:0.277247\n",
      "Stopping. Best iteration:\n",
      "[1415]\ttrain-gini:0.441621\tvalid-gini:0.27727\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    'min_child_weight': 10.0,\n",
    "    'objective': 'binary:logistic',\n",
    "    'max_depth': 7,\n",
    "    'max_delta_step': 1.8,\n",
    "    'colsample_bytree': 0.4,\n",
    "    'subsample': 0.8,\n",
    "    'eta': 0.025,\n",
    "    'gamma': 0.65,\n",
    "    'num_boost_round' : 700\n",
    "}\n",
    "\n",
    "xgb_oof_train, xgb_oof_test = get_oof_xgb(X, y, test) # XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_predictions_train = pd.DataFrame( {'RandomForest': rf_oof_train.ravel(),\n",
    "     'DecisionTree': dt_oof_train.ravel(),\n",
    "     'ExtraTrees': et_oof_train.ravel(),\n",
    "  #   'AdaBoost': ada_oof_train.ravel(),\n",
    "   #  'GradientBoost': gb_oof_train.ravel(),\n",
    "     'LightGBM': lgb_oof_train.ravel(),\n",
    "     'XGBoost': xgb_oof_train.ravel()\n",
    "    })\n",
    "base_predictions_train.head()\n",
    "base_predictions_train.to_csv('base_predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_predictions_test = pd.DataFrame( {'RandomForest': rf_oof_test.ravel(),\n",
    "     'DecisionTree': dt_oof_test.ravel(),\n",
    "     'ExtraTrees': et_oof_test.ravel(),\n",
    "  #   'AdaBoost': ada_oof_train.ravel(),\n",
    "   #  'GradientBoost': gb_oof_train.ravel(),\n",
    "     'LightGBM': lgb_oof_test.ravel(),\n",
    "     'XGBoost': xgb_oof_test.ravel()\n",
    "    })\n",
    "base_predictions_test.head()\n",
    "base_predictions_test.to_csv('base_predictions_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train = np.concatenate(( et_oof_train, rf_oof_train, ada_oof_train, gb_oof_train,lgb_oof_train,xgb_oof_train), axis=1)\n",
    "#x_test = np.concatenate(( et_oof_test, rf_oof_test, ada_oof_test, gb_oof_test, lgb_oof_test,xgb_oof_test), axis=1)\n",
    "x_train = np.concatenate(( et_oof_train,lgb_oof_train,xgb_oof_train), axis=1)\n",
    "x_test = np.concatenate(( et_oof_test, lgb_oof_test,xgb_oof_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1/5]\n",
      "[0]\ttrain-gini:0.070798\tvalid-gini:0.066703\n",
      "Multiple eval metrics have been passed: 'valid-gini' will be used for early stopping.\n",
      "\n",
      "Will train until valid-gini hasn't improved in 130 rounds.\n",
      "[10]\ttrain-gini:0.780813\tvalid-gini:0.148646\n",
      "[20]\ttrain-gini:0.772707\tvalid-gini:0.173647\n",
      "[30]\ttrain-gini:0.770504\tvalid-gini:0.17463\n",
      "[40]\ttrain-gini:0.77126\tvalid-gini:0.175379\n",
      "[50]\ttrain-gini:0.773022\tvalid-gini:0.176712\n",
      "[60]\ttrain-gini:0.777408\tvalid-gini:0.189046\n",
      "[70]\ttrain-gini:0.775344\tvalid-gini:0.188741\n",
      "[80]\ttrain-gini:0.775689\tvalid-gini:0.188221\n",
      "[90]\ttrain-gini:0.781383\tvalid-gini:0.188756\n",
      "[100]\ttrain-gini:0.784398\tvalid-gini:0.207066\n",
      "[110]\ttrain-gini:0.78708\tvalid-gini:0.207107\n",
      "[120]\ttrain-gini:0.788555\tvalid-gini:0.220791\n",
      "[130]\ttrain-gini:0.794844\tvalid-gini:0.222259\n",
      "[140]\ttrain-gini:0.798594\tvalid-gini:0.22249\n",
      "[150]\ttrain-gini:0.802365\tvalid-gini:0.222664\n",
      "[160]\ttrain-gini:0.806315\tvalid-gini:0.222613\n",
      "[170]\ttrain-gini:0.812845\tvalid-gini:0.225163\n",
      "[180]\ttrain-gini:0.817426\tvalid-gini:0.224805\n",
      "[190]\ttrain-gini:0.820313\tvalid-gini:0.224448\n",
      "[200]\ttrain-gini:0.821703\tvalid-gini:0.226323\n",
      "[210]\ttrain-gini:0.827393\tvalid-gini:0.229316\n",
      "[220]\ttrain-gini:0.829165\tvalid-gini:0.230474\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-297-4ce635d08ce7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     mdl = xgb.train(params, d_train, 4000, watchlist, early_stopping_rounds=130, \n\u001b[1;32m---> 33\u001b[1;33m                     \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgini_xgb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaximize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m                     \u001b[1;31m#earning_rates = lambda iter, ed: 0.025 * (0.997 ** iter)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m                    )\n",
      "\u001b[1;32mC:\\Users\\Damygame\\Anaconda2\\lib\\site-packages\\xgboost\\training.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, learning_rates, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    203\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Damygame\\Anaconda2\\lib\\site-packages\\xgboost\\training.pyc\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[1;31m# check evaluation result.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m             \u001b[0mbst_eval_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst_eval_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSTRING_TYPES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbst_eval_set\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Damygame\\Anaconda2\\lib\\site-packages\\xgboost\\core.pyc\u001b[0m in \u001b[0;36meval_set\u001b[1;34m(self, evals, iteration, feval)\u001b[0m\n\u001b[0;32m    870\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'[%d]'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    871\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mdmat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 872\u001b[1;33m                 \u001b[0mfeval_ret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdmat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdmat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    873\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeval_ret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    874\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeval_ret\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-259-2e702e1de212>\u001b[0m in \u001b[0;36mgini_xgb\u001b[1;34m(preds, dtrain)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgini_xgb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     \u001b[0mgini_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgini_normalized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;34m'gini'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgini_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-259-2e702e1de212>\u001b[0m in \u001b[0;36mgini_normalized\u001b[1;34m(a, p)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgini_normalized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgini\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mgini\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgini_lgb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-259-2e702e1de212>\u001b[0m in \u001b[0;36mgini\u001b[1;34m(y, pred)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgini\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlexsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \u001b[0mgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mgs\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kfold = 5\n",
    "skf = StratifiedKFold(n_splits=kfold, random_state=42)\n",
    "\n",
    "params = {\n",
    "   # 'min_child_weight': 5.0,\n",
    "    'objective': 'binary:logistic',\n",
    "    'max_depth': 5,\n",
    "    'max_delta_step': 1.8,\n",
    "    'colsample_bytree': 0.5,\n",
    "    'subsample': 0.5,\n",
    "    'eta': 0.0005,\n",
    "#    'gamma': 100.85,\n",
    "    'num_boost_round' : 700\n",
    "}\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub['id'] = test_id\n",
    "sub['target'] = np.zeros_like(test_id)\n",
    "\n",
    "sum_valid_gini = 0\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(x_train, y)):\n",
    "    print('[Fold %d/%d]' % (i + 1, kfold))\n",
    "    X_train, X_valid = x_train[train_index], x_train[test_index]\n",
    "    y_train, y_valid = y[train_index], y[test_index]\n",
    "    # Convert our data into XGBoost format\n",
    "    d_train = xgb.DMatrix(X_train, y_train)\n",
    "    d_valid = xgb.DMatrix(X_valid, y_valid)\n",
    "    d_test = xgb.DMatrix(x_test)\n",
    "    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "\n",
    "    mdl = xgb.train(params, d_train, 4000, watchlist, early_stopping_rounds=130, \n",
    "                    feval=gini_xgb, maximize=True, verbose_eval=10,\n",
    "                    learning_rates = lambda iter, ed: 0.0005 * (0.997 ** iter)\n",
    "                   )\n",
    "\n",
    "    print('[Fold %d/%d Prediciton:]' % (i + 1, kfold))\n",
    "    # Predict on our test data\n",
    "    p_test = mdl.predict(d_test)\n",
    "    p_valid = mdl.predict(d_valid)\n",
    "    sub['target'] += p_test/kfold\n",
    "    sum_valid_gini += gini_normalized(y_valid, p_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('EstimatedGini: ', calcginiindex(sub['target'].values))\n",
    "#sum_valid_gini = 0.279847 + 0.288112 + 0.282968 + 0.291635 + 0.27727\n",
    "print('Valid gini:', sum_valid_gini/kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv('ensemble'+ str(sum_valid_gini/kfold) +'.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FOREST\n",
      "('Fold :', 0, 'Train Gini:', 0.87716051078130197, 'Valid Gini:', 0.042669514555137913)\n",
      "('Fold :', 1, 'Train Gini:', 0.80026221117762508, 'Valid Gini:', 0.88101619215005911)\n",
      "('Fold :', 2, 'Train Gini:', 0.79998561362061993, 'Valid Gini:', 0.88215553019869741)\n",
      "('Fold :', 3, 'Train Gini:', 0.80218687544262712, 'Valid Gini:', 0.87396872870139297)\n",
      "('Fold :', 4, 'Train Gini:', 0.8010473675368841, 'Valid Gini:', 0.87868734811001514)\n",
      "('New best gini:', 0.7589042875002795)\n"
     ]
    }
   ],
   "source": [
    "best_gini = 0\n",
    "rf_params = {\n",
    "    'n_jobs': 6,\n",
    "    'n_estimators': 40,\n",
    "    'warm_start': True, \n",
    "    'max_depth': 3\n",
    "}\n",
    "rf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\n",
    "\n",
    "print('RANDOM FOREST')\n",
    "rf_train, rf_test = get_oof(rf,x_train, y, x_test) # Random Forest\n",
    "\n",
    "curr_gini = calcginiindex(rf_test)\n",
    "if curr_gini > best_gini:\n",
    "    print('New best gini:', curr_gini)\n",
    "    best_gini = curr_gini\n",
    "    best_params = pd.DataFrame(rf_params, index=[1])\n",
    "else:\n",
    "    print('Curr gini:', curr_gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({\n",
    "    'id': test_id,\n",
    "    'target': (et_oof_test.ravel() + lgb_oof_test.ravel() + xgb_oof_test.ravel())/3\n",
    "})\n",
    "sub.to_csv('ensemble_medium_v1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34668668191145868"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcginiindex(sub['target'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
